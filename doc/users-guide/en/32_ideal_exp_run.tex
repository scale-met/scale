\section{How to execute model} \label{sec:ideal_exp_run}
%====================================================================================


\subsubsection{Experimental setup}
For this tutorial for an ideal experiment, a case of cumulus cloud convection is used.
In this experiment, a cumulus appears and develops in a quasi-2D model
by providing a typical atmospheric vertical profile
and an initial disturbance in the lower troposphere.
Table \ref{tab:setting_ideal} shows the experimental settings.

\begin{table}[htb]
\begin{minipage}{150mm}
\begin{center}
\caption{Experimental settings of ideal experiment}
\begin{tabularx}{150mm}{|l|X|X|} \hline
 \rowcolor[gray]{0.9} ~~ & Configuration & Note \\ \hline
 Number of MPI processes& 2: eastward direction, 1: northward direction & 2 MPI parallel \\ \hline
 Horizontal grid spacing & 500m: eastward direction, 500m :northward direction & The quasi 2 dimensional experiment in the eastward and vertical directions. \\ \hline
 Number of horizontal grids & 40: eastward direction, 2: northward direction\footnote{In the current version, the pure 2D experimental framework is not prepared. In this case, the initial conditions with the same values are set northward. Thus, the setting corresponds to a 2D experiment. Further, the number of grids northward should be same as the number of halos. Refer to Section \ref{subsec:atmos_dyn_scheme} for the required numbers of halos.} &  \\ \hline
 Number of vertical layers & 97 layers with model top of 20 km & Stretched grid with finer resolution in the lower layers. \\ \hline
 Lateral boundary condition & Periodic condition & both eastward and northward \\ \hline
 Time step & 5 s      &  10 s in microphysics scheme\\ \hline
 Integration time     & 3,600 s & The time step is 720.\\ \hline
 Time interval of data output & 300 s  &  \\ \hline
 Physical scheme & Only the microphysics scheme &
 6-class single-moment bulk model \citep{tomita_2008} \\ \hline
 Initial vertical profile & GCSS Case1 squall line \citep{Redelsperger2000}&
 The wind profile based on \citet{Ooyama_2001} is given as the vertical shear. \\ \hline
 Initial disturbance & Warm bubble & Horizontal radius of 4 km and 
 vertical radius of 3km with  maximum intensity of 3K.\\ \hline
\end{tabularx}
\label{tab:setting_ideal}
\end{center}
\end{minipage}
\end{table}


\subsubsection{Preparations} %\label{subsec:ideal_exp_prepare}
%------------------------------------------------------

This ideal experiment is conducted in the directory of \verb|scale-rm/test/tutorial/ideal|.  Move to this directory and  create a static link to the executable binary in scale-{\version}/bin as follows:
\begin{verbatim}
  $ cd scale-rm/test/tutorial/ideal
  $ ln -s ../../../../bin/scale-rm      ./
  $ ln -s ../../../../bin/scale-rm_init ./
\end{verbatim}
where ``\verb|scale-rm|'' is the executable binary of the simulation
and  ``\verb|scale-rm_init|'' is a tool for creating the initial and the boundary conditions.


\subsubsection{Creating initial conditions} \label{subsec:ideal_exp_init}
%------------------------------------------------------

To create the initial conditions, the configuration file for \verb|scale-rm_init| is required.
The configuration file \verb|init_R20kmDX500m.conf| has been prepared
according to Table \ref{tab:setting_ideal}.
Reading the configuration file, \verb|scale-rm_init| calculates the stratified atmospheric structure and the initial disturbance.

The general form of the executable command in \scalerm is given as follows:
\begin{verbatim}
  $ mpirun -n [the number of processes] \\
    [executable binary name] [the configuration file]
\end{verbatim}
The number of processes using MPI parallel processing is given at [the number of processes]. The name of the executable binary is given to [executable binary name],  such as \verb|scale-rm|, \verb|scale-rm_init|, and so on.  The configuration file, where the experimental settings are described, is given to [the configuration file].
In the case that
the configuration file \verb|init_R20kmDX500m.conf| is used to conduct \verb|scale-rm_init| using two-MPI parallel, give the command to execute \verb|scale-rm_init| as follows:
\begin{verbatim}
  $ mpirun  -n  2  ./scale-rm_init  init_R20kmDX500m.conf
\end{verbatim}
\noindent 
If it is successfully completed, the following message is output in the command line:

\msgbox{
 *** Start Launch System for SCALE-RM\\
 *** Execute preprocess? :  T\\
 *** Execute model?      :  F\\
 *** a single comunicator\\
 *** a single comunicator\\
 *** End   Launch System for SCALE-RM\\
}

Through the above, the following three files are generated under the given directory:
\begin{verbatim}
  init_LOG.pe000000
  init_00000101-000000.000.pe000000.nc
  init_00000101-000000.000.pe000001.nc
\end{verbatim}
The entire calculation domain is horizontally divided by the number of MPI processes.
The number followed by \verb|pe| in the file name shows the process number of MPI.
In log file \verb|init_LOG.pe000000|,
detailed information that is not displayed in the command-line is recorded.
Although the two MPI processes are used in the case,
only the log file of the 0th process (master rank) is output as default.
If the execution is normally concluded, the statements below are output at the end of this LOG file:

\msgbox{
 ++++++ Finalize MPI...\\
 ++++++ MPI is peacefully finalized\\
}

The two files
\verb|init_00000101-000000.000.pe000000.nc|\\ and \verb|init_00000101-000000.000.pe000001.nc| are the initial-condition files, and each is approximately 100 KB.
The file whose name ends with ``.nc''  is formatted by \netcdf.
It can be directly read by GPhys/Ruby-DCL and ncview.


\subsubsection{Execution of simulation} %\label{subsec:ideal_exp_run}
%------------------------------------------------------

The number of parallel process is required to be the same as that when creating the initial conditions.
The configuration file for the run is \verb|run_R20kmDX500m.conf|.
\begin{verbatim}
  $ mpirun  -n  2  ./scale-rm  run_R20kmDX500m.conf
\end{verbatim}

If a computer satisfying the necessary requirements is used,
the calculation is concluded within two minutes.
The following three files are then generated under the given directory:
\begin{verbatim}
  LOG.pe000000
  history.pe000000.nc
  history.pe000001.nc
\end{verbatim}
%In \verb|LOG.pe000000|, the detailed log that is not displayed in the command line is recorded.
When the execution concludes normally,
the following message is output at the end of this LOG file:
\msgbox{
 ++++++ Finalize MPI...\\
 ++++++ MPI is peacefully finalized\\
}
The two files \verb|history.pe000000.nc| and \verb|history.pe000001.nc| are history files containing the results of the calculation. They are formatted by \netcdf, and each file is approximately 1.4 MB. 
