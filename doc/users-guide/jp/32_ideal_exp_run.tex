\section{モデルの実行方法} \label{sec:ideal_exp_run}
%====================================================================================

\subsubsection{実験設定}
%====================================================================================

理想実験のチュートリアルとして、積雲対流の理想実験を実施する。
この実験では、典型的な大気の鉛直分布および対流圏下層に初期擾乱を与え、
積乱雲が発生し発達する様子を準2次元モデルにおいて表現する。
表\ref{tab:setting_ideal}に、実験設定を示す。

\begin{table}[htb]
\begin{minipage}{150mm}
\begin{center}
\caption{理想実験の実験設定}
\begin{tabularx}{150mm}{|l|X|X|} \hline
 \rowcolor[gray]{0.9} 項目 & 設定内容 & 備考 \\ \hline
 MPIプロセス数 & 東西：2、南北：1 & 計2プロセスでの並列計算を行う \\ \hline
 水平格子間隔 & 東西：500 m、南北：500 m & 東西-鉛直の面を切り取った準2次元実験である \\ \hline
 水平格子点数 & 東西：40、南北：2\footnote{現在は２次元実験を行うための枠組みは用意されていないが、{\YDIR}に同じ値をもつ初期値を与える事で２次元実験に相当する実験を行うことが可能である。この場合、ハロの格子数と同じ数の格子数を{\YDIR}に設定する必要がある。ハロに必要な格子数については\ref{subsec:atmos_dyn_scheme}参照。} &  \\ \hline
 鉛直層数     & 97層（モデル上端 20 km）& 下層ほど細かい層厚を持ったストレッチ格子の設定である \\ \hline
 側面境界条件 & 周期境界 & 東西、南北境界とも \\ \hline
 積分時間間隔 & 5 sec      & 雲微物理スキームは10 sec毎 \\ \hline
 積分期間     & 3,600 sec  & 720 steps \\ \hline
 データ出力間隔 & 300 sec  &  \\ \hline
 物理スキーム & 雲微物理モデルのみ使用 &
 6-class single moment bulk model \citep{tomita_2008} \\ \hline
 初期の鉛直分布 & GCSS Case1 squall-line \citep{Redelsperger2000}&
 風の分布は、\citet{Ooyama_2001}に基づいた鉛直シアを与える \\ \hline
 初期擾乱 & 暖気塊(warm bubble) & 水平 4 km、
 鉛直 3 kmの半径を持ち、極大値が 3 Kの暖気塊を置く\\ \hline
\end{tabularx}
\label{tab:setting_ideal}
\end{center}
\end{minipage}
\end{table}


\subsubsection{準備} %\label{subsec:ideal_exp_prepare}
%------------------------------------------------------
理想実験は、ディレクトリ\verb|scale-rm/test/tutorial/ideal|の中で実行する。
このディレクトリに移動し、scale-{\version}/bin にある実行バイナリへの静的リンクを張る。
\begin{alltt}
  $ cd scale-rm/test/tutorial/ideal
  $ ln -s ../../../../bin/scale-rm      ./
  $ ln -s ../../../../bin/scale-rm_init ./
\end{alltt}
ここで、「\verb|scale-rm|」はモデル本体、
「\verb|scale-rm_init|」は初期値/境界値作成ツールである。

\subsubsection{初期値の作成} \label{subsec:ideal_exp_init}
%------------------------------------------------------
初期値を作成するには、\verb|scale-rm_init|に与える設定ファイルが必要である。
設定ファイル\\ \verb|init_R20kmDX500m.conf| には、表\ref{tab:setting_ideal} に対応する実験設定が書かれている。
この設定ファイルを読み込ませると、大気の成層構造と初期擾乱が計算される。

\scalerm の実行コマンドの一般的な形式は、
\begin{alltt}
  $ mpirun  -n  [プロセス数]  [実行バイナリ名]  [設定ファイル]
\end{alltt}
である。
[プロセス数]にはMPI並列で使用したいプロセス数、
[実行バイナリ]には\verb|scale-rm|や\verb|scale-rm_init|といった実行バイナリ名を指定する。
そして、[設定ファイル]には実験設定を記述した設定ファイルを指定する。
%
2 プロセスのMPI並列計算を行うように、
\verb|init_R20kmDX500m.conf|を設定している場合は、
\verb|scale-rm_init|を実行するコマンドは
\begin{alltt}
  $ mpirun  -n  2  ./scale-rm_init  init_R20kmDX500m.conf
\end{alltt}
%
と記述する。
\noindent 実行が成功すれば、コマンドラインのメッセージは
下記のように表示される。\\

\noindent {\small {\gt
\fbox{
\begin{tabularx}{150mm}{l}
 *** Start Launch System for SCALE-RM\\
 *** Execute preprocess? :  T\\
 *** Execute model?      :  F\\
 *** a single comunicator\\
 *** a single comunicator\\
 *** End   Launch System for SCALE-RM\\
\end{tabularx}
}}}\\


\noindent この実行によって、下記の3つのファイルが、現在のディレクトリ下に作成される。
\begin{alltt}
  init_LOG.pe000000
  init_00000101-000000.000.pe000000.nc
  init_00000101-000000.000.pe000001.nc
\end{alltt}
計算領域の全体は、MPIプロセス数だけ水平分割される。
ファイル名において\verb|pe|に続く番号は、MPIのプロセス番号を示している。
ログファイル(\verb|init_LOG.pe000000|)には、
コマンドラインには表示されない詳細情報が記録されている。
この例では 2 つのMPIプロセスを使用しているが、
0 番目のプロセス（マスターランク）に対するログファイルだけがデフォルト設定では出力される。
%すべてのプロセスの実行ログを出力するよう設定を変更することも出来る。
実行が正常に終了すれば、LOGファイルの最後に\\
\msgbox{
 +++++ finalize MPI...\\
 +++++ MPI is peacefully finalized\\
}
が出力される。

\verb|init_00000101-000000.000.pe000000.nc|と\verb|init_00000101-000000.000.pe000001.nc|の
2つのファイルは初期値ファイルであり、それぞれ約 600 KBのファイルサイズになる。
%計算領域全体を2つのMPIプロセスで分割し担当するため、
%2つのファイルが生成される。
%もし、4-MPI並列で実行すれば、4つの初期値ファイルが生成される。
ファイル名の末尾が「.nc」で終わるファイルは {\netcdf}形式のファイルであり、
GPhys/Ruby-DCL や ncview によって直接読み込める。



\subsubsection{シミュレーションの実行} \label{subsec:ideal_exp_run}
%------------------------------------------------------
プロセス並列数は、初期値を作成した時と同じにする必要がある。
シミュレーション実行用の設定ファイルは \verb|run_R20kmDX500m.conf| である。
\begin{alltt}
  $ mpirun  -n  2  ./scale-rm  run_R20kmDX500m.conf
\end{alltt}

本書の必要要件にあった計算機であれば、2 分程度で計算が終わる。
この実行によって、3つのファイル
\begin{alltt}
  LOG.pe000000
  history.pe000000.nc
  history.pe000001.nc
\end{alltt}
が、現在のディレクトリ下に作成される。
実行が正常に終了すれば、LOGファイルの最後に
\msgbox{
 +++++ finalize MPI...\\
 +++++ MPI is peacefully finalized\\
}
と出力される。
\verb|history.pe000000.nc| と \verb|history.pe000001.nc|
の2つのファイルは、計算結果を含むヒストリファイルである。
これらのファイル形式は{\netcdf}であり、各ファイルのサイズは約5.8 MBである。
